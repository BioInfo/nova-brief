# Nova Brief - Deep Research Agent

A fast, reliable deep-research agent that plans, searches, reads, verifies, and writes analyst-grade, cited briefs.

## Features

üîç **End-to-End Research Pipeline**
- **Planner**: Transforms topics into comprehensive search strategies
- **Searcher**: Multi-source web search with domain filtering and deduplication  
- **Reader**: Content extraction from HTML and PDF sources
- **Analyst**: LLM-powered information synthesis with structured claims
- **Verifier**: Citation validation and coverage enforcement
- **Writer**: Professional report generation with numbered citations

ü§ñ **OpenRouter Integration**
- Uses OpenRouter API with Cerebras provider pinning
- Model: `openai/gpt-oss-120b` for high-performance research
- Structured JSON outputs via JSON Schema validation

üìä **Professional Output**
- 800-1200 word reports with proper citations
- Markdown format with numbered references
- JSON export capability for programmatic use
- Comprehensive metrics and source tracking

üéØ **Quality Assurance**
- Strict citation policy: all claims backed by sources
- Domain diversity enforcement
- Content quality filtering and validation
- Iterative refinement with coverage targets

## Quick Start

### Prerequisites

- Python 3.9+ 
- OpenRouter API key (get one at [openrouter.ai](https://openrouter.ai))
- `uv` package manager (recommended) or `pip`

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd nova-brief
   ```

2. **Install dependencies**
   ```bash
   # Using uv (recommended)
   uv sync
   
   # Or using pip
   pip install -e .
   ```

3. **Configure environment**
   ```bash
   cp .env.example .env
   # Edit .env and add your OPENROUTER_API_KEY
   ```

4. **Run the application**
   ```bash
   # Using uv
   uv run streamlit run src/app.py
   
   # Or using python directly
   python -m streamlit run src/app.py
   ```

5. **Open your browser**
   ```
   http://localhost:8501
   ```

## Usage

### Web Interface

1. **Enter Research Topic**: Provide a specific topic for investigation
2. **Configure Settings**: Adjust research rounds, domain filters, timeouts
3. **Start Research**: Click "Start Research" to begin the pipeline
4. **View Results**: Monitor progress and review the generated report
5. **Export**: Download as Markdown or JSON

### Command Line (Advanced)

```bash
# Run tests
uv run python tests/test_mvp.py

# Run evaluation harness
uv run python eval/harness.py

# Quick evaluation
uv run python eval/harness.py --quick --max-topics 3
```

## Configuration

Configure Nova Brief via environment variables in `.env`:

```bash
# Required
OPENROUTER_API_KEY=your_api_key_here

# Optional (with defaults)
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
MODEL="openai/gpt-oss-120b"
SEARCH_PROVIDER=duckduckgo
MAX_ROUNDS=3
PER_DOMAIN_CAP=3
FETCH_TIMEOUT_S=15
ENABLE_CACHE=false
LOG_LEVEL=INFO
USER_AGENT=NovaBrief-Research/0.1
```

### Advanced Settings

- **MAX_ROUNDS**: Number of iterative research rounds (1-5)
- **PER_DOMAIN_CAP**: Maximum results per domain (prevents over-reliance)
- **FETCH_TIMEOUT_S**: Timeout for web page fetching
- **Domain Filters**: Include/exclude specific domains in research

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Streamlit UI  ‚îÇ    ‚îÇ  Agent Pipeline ‚îÇ    ‚îÇ  OpenRouter API ‚îÇ
‚îÇ                 ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ                 ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ                 ‚îÇ
‚îÇ ‚Ä¢ Topic Input   ‚îÇ    ‚îÇ ‚Ä¢ Planner       ‚îÇ    ‚îÇ ‚Ä¢ Cerebras      ‚îÇ
‚îÇ ‚Ä¢ Configuration ‚îÇ    ‚îÇ ‚Ä¢ Searcher      ‚îÇ    ‚îÇ ‚Ä¢ GPT-OSS-120B  ‚îÇ
‚îÇ ‚Ä¢ Progress      ‚îÇ    ‚îÇ ‚Ä¢ Reader        ‚îÇ    ‚îÇ ‚Ä¢ JSON Schema   ‚îÇ
‚îÇ ‚Ä¢ Results       ‚îÇ    ‚îÇ ‚Ä¢ Analyst       ‚îÇ    ‚îÇ                 ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ ‚Ä¢ Verifier      ‚îÇ    ‚îÇ                 ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ ‚Ä¢ Writer        ‚îÇ    ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Web Search    ‚îÇ    ‚îÇ  Content Tools  ‚îÇ    ‚îÇ  Observability  ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ
‚îÇ ‚Ä¢ DuckDuckGo    ‚îÇ    ‚îÇ ‚Ä¢ HTML Extract  ‚îÇ    ‚îÇ ‚Ä¢ Structured    ‚îÇ
‚îÇ ‚Ä¢ Domain Filter ‚îÇ    ‚îÇ ‚Ä¢ PDF Parsing   ‚îÇ    ‚îÇ   Logging       ‚îÇ
‚îÇ ‚Ä¢ Deduplication ‚îÇ    ‚îÇ ‚Ä¢ Content Clean ‚îÇ    ‚îÇ ‚Ä¢ Tracing       ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ ‚Ä¢ Chunking      ‚îÇ    ‚îÇ ‚Ä¢ Metrics       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Development

### Project Structure

```
nova-brief/
‚îú‚îÄ‚îÄ src/                    # Source code
‚îÇ   ‚îú‚îÄ‚îÄ agent/             # Agent pipeline components
‚îÇ   ‚îú‚îÄ‚îÄ tools/             # Web search, fetch, parse tools
‚îÇ   ‚îú‚îÄ‚îÄ providers/         # LLM and search providers
‚îÇ   ‚îú‚îÄ‚îÄ storage/           # Data models and schemas
‚îÇ   ‚îú‚îÄ‚îÄ observability/     # Logging and tracing
‚îÇ   ‚îú‚îÄ‚îÄ app.py            # Streamlit UI
‚îÇ   ‚îî‚îÄ‚îÄ config.py         # Configuration management
‚îú‚îÄ‚îÄ tests/                 # Test suite
‚îú‚îÄ‚îÄ eval/                  # Evaluation harness
‚îú‚îÄ‚îÄ docs/                  # Documentation
‚îú‚îÄ‚îÄ memory-bank/           # Project context and decisions
‚îú‚îÄ‚îÄ pyproject.toml        # Project configuration
‚îî‚îÄ‚îÄ .env.example          # Environment template
```

### Running Tests

```bash
# Full test suite
uv run python tests/test_mvp.py

# Evaluation on sample topics
uv run python eval/harness.py --quick
```

### Development Setup

```bash
# Install development dependencies
uv sync --dev

# Run with development logging
LOG_LEVEL=DEBUG uv run streamlit run src/app.py
```

## API Reference

### Core Functions

#### `run_research_pipeline(topic, constraints)`
Execute the complete research pipeline for a given topic.

**Parameters:**
- `topic` (str): Research topic
- `constraints` (Constraints): Configuration constraints

**Returns:**
- Dictionary with research state, report, and metrics

#### Agent Components

Each agent component follows a consistent interface:

```python
async def component_function(inputs) -> Dict[str, Any]:
    """
    Returns:
        {
            "success": bool,
            "data": Any,
            "metadata": Dict[str, Any],
            "error": Optional[str]
        }
    """
```

## Troubleshooting

### Common Issues

**"OpenRouter API key required"**
- Ensure `OPENROUTER_API_KEY` is set in your `.env` file
- Verify the API key is valid at [openrouter.ai](https://openrouter.ai)

**"No search results found"**
- Check internet connectivity
- Try broader search terms
- Adjust domain filters if too restrictive

**"Content extraction failed"**
- Some sites may block automated access
- PDF content requires accessible URLs
- Check robots.txt compliance settings

**"Memory/Performance issues"**
- Reduce `MAX_ROUNDS` for faster execution
- Lower `PER_DOMAIN_CAP` to limit sources
- Use `--quick` mode for evaluation

### Debug Mode

Enable detailed logging:

```bash
LOG_LEVEL=DEBUG uv run streamlit run src/app.py
```

### Performance Tuning

For faster research (with reduced quality):
```bash
# Quick research settings
MAX_ROUNDS=1
PER_DOMAIN_CAP=2
FETCH_TIMEOUT_S=10
```

## Roadmap

### Current: MVP (Stage 1)
- ‚úÖ Complete agent pipeline
- ‚úÖ OpenRouter + Cerebras integration  
- ‚úÖ Web search and content extraction
- ‚úÖ Streamlit UI
- ‚úÖ Basic evaluation harness

### Planned: Stage 2
- Async HTTP client with rate limiting
- SQLite caching layer
- Pydantic v2 data models
- Enhanced evaluation metrics

### Future: Stage 3+
- LangGraph orchestration
- REST API with authentication
- OpenTelemetry observability
- Next.js web interface

## Contributing

1. Fork the repository
2. Create a feature branch
3. Run tests: `uv run python tests/test_mvp.py`
4. Submit a pull request

## License

[Your License Here]

## Support

For questions and support:
- Check existing issues in the repository
- Review troubleshooting section
- Create a new issue with detailed information

---

**Built with**: Python 3.9+, Streamlit, OpenRouter, Cerebras, DuckDuckGo